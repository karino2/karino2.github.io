---
title: "結果を制御下に置く必要のある機械学習"
date: 2019-07-11 03:17:41
---

今朝、トレーニングセットの合成のためのDSLが無事完成した。
ここまでで、手書き数式認識、プロジェクト名「手が式」のために、

- 自分で実機でトレーニングセット作るためのアプリ
- kotlin上でのテンソルライブラリ
- トレーニングセット合成のためのDSL

となかなかいろいろ発明をしている。
これは機械学習のプロジェクトとしては結構珍しいと思う。
その特殊性がどこからくるのか、をちょっと考えてみたい。

今回のモデルの要求の珍しい事の一つに、結果を制御下に置く事をかなり優先している事が挙げられる。
普通、機械学習の応用としては、結果にある程度の不確実性がある方が普通で、
制御下にあるのが重要な用途では機械学習の応用は失敗しがちに思う。
これまでは、むしろそうじゃない用途を探すのが機械学習屋の腕の見せ所、という部分があった。

結果を制御下に置く必要性というのは、アプリの機能的なものの一部として開発している、という事情があると思う。
サービスの機能の一部に機械学習が使われる事は良くあるのだけど、
今回みたいなケースは珍しい。その違いはどこにあるんだろう？

今回の手が式は、ある種のIMEだ。
候補はいろいろあっても、最終的に確定した結果というのはユーザーの望む物だけが確定される。
最終的なアウトプットの精度は100%である必要がある（第一候補が100%という訳では無い）。
これは珍しい。

普通は、手書きの数式認識というと、OCR的な問題設定をしたくなる。
画像を渡すと数式が出る。
これだと精度がそれなりに高くても、間違いが正せない。だからこういう問題設定ではいけない。

「機械学習では普通こうしたくなる」というある種の問題のクラスがある。
そこにはいくつかの機械学習に向いた性質がある。例えば結果を制御下に置く重要度がそこまで高くない、とか。
その分、こちらの問題は、（長く取り組まれてきたものに関しては）すごく難しい要素を含んでいても、結構いいところまで解決出来るような状態になっている。
かなり長い系列長の相関とかそういうの。
便宜上この手の問題を「クラス1の問題」と呼ぶ事にしよう。

一方で、そうでない問題のクラスでも、機械学習が有効な分野というのがすごく増えた。
これはクラス1の問題ですごく難しい問題にアプローチ出来るようになった結果、
より簡単な問題ならクラス1の問題じゃなくてもなんとかなるようになった、
という事だと思う。
例えば結果をユーザーの制御下に置きたい、という問題のクラス。
これを「クラス2」と呼ぶ事にしよう。

「クラス2」には機械学習に向いていない性質がいくつかある代わりに、「クラス1」の最先端よりも簡単な問題を設定する事にすると、解ける場合がある。
もちろん「クラス2」かつ「難しい」問題はいくらでもあるのだが、それらは現時点では解けない。

「クラス2」が解けるためには、「クラス1」の問題で、普通の問題よりも難しい問題が解けるようになっている必要がある。
同じ難度の問題なら解ける場合もあるが、相当な幸運が必要で、
ここまで手が式を開発してみた印象としては、同じ難度では現実的にはほぼ解けない。

例えば、Encoder-Decoder型のモデルは、2015年くらいではクラス2の問題は解けない。
一方で2018年の末だとクラス2の問題でも基本的なの（2015年にクラス1で解けてたくらいの系列長や組み合わせの数など）は解ける。
これはconvolutionで系列データを扱うための研究が溜まってきたり、Transformerなどのようなより強力かつシンプルなモデルが登場した事などの影響と、
その研究分野の進展でkerasなどのライブラリで下回りが揃った事などがある。

それより先に流行った分野、例えば画像認識だと、
2017年くらいにはクラス2で解ける問題がそれなりに出来てきたと思う。
あまり挑んでいる人は見かけないが。

ただどちらにせよクラス2の問題に挑めるかな？というくらいいろいろ整備が進んだのはかなり最近の事で、実務的には今年とか去年くらいがせいぜいじゃないか。
だからやってる企業とかもまだほとんど無い。

クラス2の問題はモデルの挙動をユーザーの制御下におけるようにするために、何かを妥協することになる。
例えばデータセットを限定して、解ける問題の数を絞るとか。
さらにデータセットの分布を細かく制御して狙った挙動をさせる必要がある。
ある程度ディープなモデルの挙動を制御下に置く為には、UI的な工夫とトレーニングセットの分布を制御する方向の2つを合わせて達成する必要があるのが普通と思う。

トレーニングセットの分布を制御するためには、トレーニングセットにある種の制約が発生する。
ふつう機械学習のプロジェクトでは、なるべく人手を掛けないデータセットに対してトレーニングさせるのが理想である。
データ自体はどんどん増えていくしたくさんあるが、人手は限られているので、人手を掛けると使えるデータが減る。
なるべくデータが多い方が良い機械学習においては、なるべく元のままのデータで学習出来るように頭を使う方が良い結果になる事が多い。
単にデータがたくさんあるだけでいろいろな事が出来るからこそ機械学習の応用範囲は広いのだ。

手を入れられるデータしか解けない、
というのは、妥協というかより限定された、より簡単な狭い問題しか解けない事を意味する。
これはクラス2の問題を挑むために発生するコストだ。
これまではなるべく元データをそのままend2endで学習出来るようにするのが勝ちパターンだったので機械学習屋はそう訓練されている傾向があるが、
去年くらいから挑めるようになったこのクラス2の問題ではその思考は（今のところ）足かせになるような気がする。

手を入れる、といっても、全部プログラムで合成が出来る、という問題なら、
解くのも逆関数的な何かで厳密に解ける事が多いだろうから、
あまり機械学習を使う必要は無いかも（そんな事無い？わからん）。
だから何かしらの自然のデータがあって、それを元に合成する、みたいな問題となるのが普通と思う。
今回の例だとシンボルのデータはデータセットがあって、それのレイアウトとか並べ替えをプログラムで行っている。

モデルの挙動を制御下に置くように学習させる、というのは、
学習の過程がある種のプログラムと近い作業となる。
宣言的にプログラムを書くののさらに先、
「こういうデータセット」で学習させる、
という「こういうデータセット」を記述する。
このデータセットを記述するのは、旧来のプログラミングに相当する活動に似ている。
要求に応じた何かを記述する訳だ。
モデルのトレーニングはコンパイルに似ている。ただモデル自体も自分で試行錯誤をしていくので、コンパイラ自身も何度も変えて目的のバイナリを生成するようなイメージだ。

挙動を制御下に置くためには食わせるデータセットも細かく制御する必要がある。
そして今回のケースでは、簡単なケースは確実に解けて、なおかつ難しいケースもそこそこ頑張る、というモデルにする事で、難しいケースでうまく行かない場合はユーザー側が簡単なケースの組み合わせで目的を達成出来るように作る。
IMEで文単位で変換してうまく行かなかったら文節単位で変換する、みたいなものだ。
こうした問題の難しさに応じた要求水準の違いを実現するためにも、
トレーニングの過程を細かく制御する必要がある。

これはクラス1の問題と大きく違う。
クラス1の問題は、データセットはそのまま実際の問題の分布であり、それを改善する事がまさに最善である。
だからデータを制御するよりも、そのままのデータに対して最強のモデルを作ろう、と頑張る。
データセットをクレンジングしたり増やしたりはするにせよ、分布を制御する事はあまり無い。
せいぜいネガティブとポジティブの比率程度のものだろう。

クラス2の問題ではデータセットを記述する事がある種のプログラミングになっているので、
これが開発のかなりの比重を占める事になる。
プログラムなので当然バグがあり、試行錯誤が必要で、最初に作ったものが本当にほしいものである事は無い。
だから開発体制もそれに応じたものが必要となる。

また、クラス2の問題は、モデル自体の構造をいじる機会もクラス1の問題より多い気がする。
より限定された問題で、けれど挙動は制御下に置きたい、というのは、
「そうなるようなモデル」になっていないと難しく、
これも最初に思いついたモデルが都合良くそんな風に振る舞う事は無い。
だからモデルのバグの頻度も多く、試行錯誤を記録する時にもこの「実はこの試行はここがバグってた」という事を記述出来る必要がある。
しかもバグは一つじゃないので、これはマルチラベル的に書ける必要がある。
これはgit的な一直線の管理ではうまく行かない。

ふむ、こうして考えてみると、結果を制御下における必要がある代わりに問題を簡単に出来る、というのが手が式の特殊さの結構多くの部分を占めている気がしてきた。
モバイルの実機だ、という別の特殊さもあるのだが。
