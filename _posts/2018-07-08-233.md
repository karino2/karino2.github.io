---
title: "PRMLの14章"
date: 2018-07-08 10:21:46
---

以前勉強会では飛ばしていいか、と思った14章（boostingとかアンサンブルの話）だが、やっぱやりたい気がしたので自分担当でやる事に。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0387310738&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

という事でここに予習内容とか書いていきます。

### ざっと最後まで読んでみた

comittee、adaboost、conditional mixtuer modelという内容。
決定木は思ったよりページ数無くて、mixtuer modelが多い。

gradient boostとかは無いのね。

adaboostはexponential errorからの解釈が書かれていて、ここの内容はなかなか良いが、最初のアルゴリズムの提示の方が先に出てくるのでこちらは分かりにくい。

幾つか重要な式変形が練習問題に回されているのでやっても良い気はする。

どうしよっかね。とりあえずこの本に沿ってまとめてみるか、それともboostingにフォーカスしてGBDTとかそのヒストグラムの話を掘り下げるか…

勉強会をどう進めるかはおいといて、ひとまず教科書の内容をまとめてみよう。

# 14.1 Bayesian model averagingとの違い

14.1では初めに、本章で扱う手法とBayesian model averagingの違いについて言及している。

結論としてはBayesian model averagingは、全部のデータがどれか一つのモデルから生成されていて（式14.6）、でもそれがどれかが分からない、データが増えればだんだんと一つに収束していく、というもの。

一方で複数のモデルをcombineする場合は、例えば式14.5の場合などでは、各データ点ごとに別々のlatent variableが考えられて、だからおのおののデータ点が別々の構成要素から生成される。

式の形は似てるけど、意味合いは違いますよ、という話っぽい。

# 14.2 Committees

スペルが難しいな。mもtもeも全部ダブるのね。どうでもいいが。

この節では、モデルを複数作って平均を取る、という方法を考える。（14.7）
一番簡単には、データを最初に分割して別々にトレーニングする。これをbootstrap aggregationとかbaggingと言うらしい。

14.8のようにあらわして、モデルが独立なら平均取るとエラー項が減ってく、という話をしている。
ただ普通相関があるのでこんなうまく行かないとか。そりゃそうだ。

# 14.3 Boosting

committeeの一種との事。
複数のモデルを組み合わせるのがcommittee、そのうち単に平均するのがbagging、順番にモデルを作り、この時前のモデルを使うのがboostingか。 

この節ではadaboostの話をしている。

## AdaBoostのアルゴリズム

まずp658に、アルゴリズムが載っている。
どうしてこういう式になるのか、については、次の14.3.1で解説がある。

問題設定としては、-1か1のどちらかをpredictするモデルを作る、というもの。

アルゴリズムの基本的なアイデアとしては、

1. 間違えたデータの重みを重くしたコスト関数を使って次のモデルをトレーニングする（wと14.15式）
2. 重み付きのデータに大して間違いの少なかったモデルを重視し、間違いが多いモデルは軽視する（アルファ）
3. 具体的なデータの重み計算では、重視するモデルの間違いをより重く見る

という感じ。

これらの式がちょうど良い物になってるかとかはこの時点では分からない。
あくまでこういう物だ、という事だけが羅列されている。

## 14.3.1 exponential errorによる解釈

adaboostのアルファやwがこの形である必然性は、アルゴリズムだけを見ると良く分からない。
14.3.1はexponential errorを最小化する、という問題を考えると自然とこれらの式が出てくる、という話。

今回もターゲットは1か-1。

![](https://i.imgur.com/F0mC1Tb.jpg)

こんなエラーを最小化していくように、fmを追加していく事を考える。

分類器yとアルファを動かして、Eを最小化する事を考える。

ただし全体を最適化するのは難しいので、greedyに求める。
つまりm-1期までの解を前提に、m期のfだけを最適化して追加する、という事を1期から繰り返す。

![](https://i.imgur.com/AArzpUz.jpg)

この式からアルファとwmの更新の式とymの学習の式が得られる。

### wmの漸化式

mを一期進めると、wmの漸化式が出てくる。ymをIndicator functionで書き直して14.26が得られて、これがwの更新の式となる。
ただしymを使ってるので、先にymをトレーニングする必要アリ。

### ymのコスト関数

という事でymをトレーニングする式を考える。
上の和を、ymが正しく分類した物とそうでない物に分けると、以下のように書ける。

![](https://i.imgur.com/8FI1j2z.jpg)

ymの最適化では第二項は定数なので第一項の最適化となる。これはadaboostのアルゴリズムの説明でのymの式と同じになる。（式14.15）

### アルファmの計算

さらにこの式で、アルファmで微分してイコール0と置くと、

![](https://i.imgur.com/j0ylL3j.jpg)

これは整理すれば式14.17になりそう。

こうして求めたfmは、もともと14.20を最小化する物だったので、この符号をpredictionで使えば良い。
これがadaboostと同じ事になる。

## 14.3.2 普通のError functionとの比較

このexponentialの誤差関数は、普通の誤差関数とは少し違う。14.3.2ではそれらがどう違うのか、という話をしている。

### 普通の誤差関数

普通の誤差関数というとロジスティック回帰の時の負の対数尤度という事になるが、これは0, 1だった。
1と-1にしたものは7.1.2でやったらしい。一応計算しておく。

尤度は

![](https://i.imgur.com/DbIgCt1.jpg)

となるので、負の対数尤度は

![](https://i.imgur.com/YhEyPms.jpg)

となる。特に難しい事は無いが、0, 1のケースと違って見慣れてないので出しておかないとピンと来ないやね。

# 14.4 Tree-based Models

いわゆる決定木のモデル。アンサンブル関係ないじゃん？という気もするが、treeのnodeごとのモデルを組み合わせている、と考えて14章に入ってる模様（だいたい定数だが…）

人間に解釈しやすいのが魅力、とか。

### 基本的なアイデア

特定のフィーチャーのsplit点より大きいか小さいかで二分木を作る。
これらはフィーチャースペースを軸と垂直な線で領域に分割していく事に相当する。
で、各領域に最終的な値を割り当てる。

これで、各サンプルが、どの領域に行くかを木をたどって判定し、最後に領域に割り当てられた値をpredictionの値とする。

これで、あとはどう分割するか、と割り当てる値をどするか、の二点の問題となる。

### regressionの場合、greedyに二乗誤差をへらす

ある領域のpredictionを、そこに属してるトレーニングサンプルの、ラベルの平均とする。

で、この平均と各ラベルとの二乗誤差をコストとし、このコストを最小にするように分割するフィーチャーと点を決めていく、というのが基本的な考え。

これだと2つのフィーチャーの組み合わせでめっさ二乗誤差が減るが一つだと駄目、みたいな時に分割出来ない気がするが…

14.4の最後にそんな事書いてあるな。

### pruning

木をどこまで伸ばすかは意外と難しくて、分割で二乗誤差があまり減らない所まで来た後も、しばらく分割を続けるとまた減り始める、という事があるらしい。

そこで一旦大きめに分割した後に、木を枝刈りしていく、という手続きを踏むらしい。
枝刈りは二乗誤差に末端のノードの数をregularizationっぽく加えたコストを最小化するように行う、とか。（式14.31）

### classificationの場合、クロスエントロピーかGini係数を使う

classificationでは、なるべくどれか一つのクラスに偏っていく方がいいので、各領域内で、あるクラスに属す確率が0か1の両極端だと低くなるようなコストを課したい。

という事でクロスエントロピーかGini係数を使うとか。

# 14.5 Conditional Mixture Models

14.5は複数の線形回帰とかロジスティック回帰のモデルの混合分布を考える、という話。
個々のモデルを条件付き確率と解釈すると、そのmixingは混合分布となる。

さらにmixing coefficientを入力の関数とみなすと、mixiture of expertsというモデルになる。

あんま面白くないので軽く流す。

### 14.5.1 線形回帰のモデルの混合

線形回帰を確率的に解釈すると、ファイとwの積を平均とするガウス分布と解釈出来る、という話があった。

そこで、K個の線形回帰のモデルを重ね合わせると、混合ガウス分布みたいな形になる。

パラメータを最尤推定する為には、各データがどの線形モデルに対応するかを表すlatent variableを考えて、EM法を適用する。

### 14.5.2 混合ロジスティックモデル

タイトルのまんま。ロジスティック回帰は条件付き確率と解釈できるので、そのまんま混合分布を考える事が出来る。

パラメータはやっぱり同じような感じでEM法で求まる。

なんというか、そのまんまの内容で別段驚きが無い。

### 14.5.3 Mixtures of experts

mixing coefficientを定数じゃなくてxの関数とすると、mixture of expertsというモデルになる。
係数は足すと1となる制約を満たす必要がある。

この係数をgating functionというらしい。LSTMみたいやね。

このgating functionをさらに多段にした物をhierarchical mixture of expertsと呼ぶ、と名前だけ紹介して本は終わる。

まぁこの辺はいいだろう。

# GBとかまで含めたboostingの話

幾つか論文を読んでみた

- Friedman 2000
- Friedman 2001
- XGBoostの論文

Friedman 2001はGradient boostの原典と思うが、XGBoostのコードや論文とは微妙に内容が違うので、原典の方をGB1、XGBoostの方をGB2と呼ぶ事にする。

adaboost、GB1、GB2は比較した方がわかりやすいと思うのだが、それぞれ微妙にノーテーションとか違って分かりにくいのでここに自分なりのまとめ方でまとめてみる。

### 両者共通の問題の定式化

まず、$$\{y, x\}$$という母集団から、$$\{y_i, x_i\}^N_1$$をサンプリングする。

あるxの関数Fとyとのロス関数Lがある。

$$L\{y, F(x)\}$$

この時に、この「母集団での」ロスの期待値を最小化する関数を$$F^*$$とする。

$$F^* = arg \min_F E_{y, x}L\{y, F(x)\}$$

この$$F^*$$を、additive  expressionで近似したい。

addtitive expressionとは、

$$F(x) = \sum^M_{m=1}f_m(x)$$

という形。


