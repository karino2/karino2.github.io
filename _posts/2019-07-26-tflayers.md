---
title: TPUEstimatorでのregularizationとtf.layersとtf.kerasについて
layout: page
---

TPUEstimatorでは、真ん中のグラフは何もいじらずによきに計らってSynchronous SGDしてくれる。
だが、入力とlossのあたりはまぁまぁ専用のコードが要る。

公式にはkerasのモデルをコンバートして行う、という事になっているが、
入力とlossのあたりのコンバートはかなり不完全で、例えばencoder-decoderなどのように入力が二つあるケースだと動かなかったりする。

そこで、Inputなどは使わずに入力回りは普通にtf.placeholderを使い、
間のレイヤはkerasの物を関数のように使いたい、というシチュエーションは結構あるだろう。

この時に、普段はmodel.fitがいろいろやってくれる所を、自分でやらなくてはいけなくなる。
公式ドキュメントは建前のコンバートを推すので、それが使えない時の情報があまり無く、stack overflowなどでは結構間違った事が書かれているので、
自分が調べた事を書いておく。

最後のlossをどうするかはあまり自信が無いので、より正しいやり方を知っている人が居たら教えてください。

### tf.layers.Conv1Dとtf.keras.Conv1Dがある

tensorflowにはtf.layersの下に、幾つかkerasのクラスをそのままラップしただけに見えるクラスが幾つかある。
また、tf.layersには一部のクラスしかないので、GRUなどいくつかの重要なクラスはtf.kerasの下にしか無い。

実装を見てみると、tf.layers.Conv1Dは例えば以下みたいになっている。(引数は...で省略している)

```
class Conv1D(keras_layers.Conv1D, base.Layer):
    def __init__(self, filters, ...):
        super(Conv1D, self).__init__(
            filters=filters,
            kernel_size=kernel_size, ...)
```

つまり、kerasのConv1Dとbase.Layerというのの多重継承になっていて、中身はinitだけで何も定義してない。
stack overflowなどでは以上から両者は同じと言っている答えしかないがこれは間違っている。（と日本語で指摘しても仕方ないが）

### tf.layers.Conv1Dの継承関係

ここからは多重継承の話になるが、keras_layers.Conv1Dは、必要な所だけを見ると、以下のような継承ツリーになっていて、

![images/2019-07-26-tflayers/keras_conv1d.png]({{"/assets/images/2019-07-26-tflayers/keras_conv1d.png" | absolute_url}})

baseの方のLayerは以下。

![images/2019-07-26-tflayers/tflayer.png]({{"/assets/images/2019-07-26-tflayers/tflayer.png" | absolute_url}})

同じkeras.Layerが親にいるのでこの多重継承の解決はちょっとややこしくて、[公式チュートリアルの多重継承](https://docs.python.org/3/tutorial/classes.html)から紹介されているドキュメントの[多重継承の解決の記事](https://www.python.org/download/releases/2.3/mro/)を読むと、以下のように解決される。

```
[keras.Conv1D, tf.Layer, keras.Layer, Object]
```

### add_loss関数

さて、ここで、add_lossという関数が問題になる。
kerasのLayerにはadd_lossという関数があって、これがregularizationのロスなどを蓄積していって、最後にfitでロスに加えてくれる。

だが、今回のようにModelクラスを使わないと、fitでいろいろやってくれる事はやってくれない。
kerasじゃない素のtensorflowだとこの辺はops.GraphKeys.REGULARIZATION_LOSSESに追加していく、という約束になっているが、kerasのadd_lossはそんな事をしてくれない。

という事で、tf.layersの方のLayerはこのadd_lossを横取りしてREGULARIZATION_LOSSESに加えてくれている。

```
# tf.layers.Layer

class Layer(base_layer.Layer):
...
  def add_loss(self, losses, inputs=None):
    ...
    super(Layer, self).add_loss(losses, inputs=inputs)
    ...
    _add_elements_to_collection(
        new_losses,
        ops.GraphKeys.REGULARIZATION_LOSSES)
```

という事で、tf.keras.Conv1Dを使っていると、weightのregularizationなどのロスを取得する手段が無いが、tf.layers.Conv1Dを使っているとこのロスをREGULARIZATION_LOSSESコレクションとして取得できる。

このロスは以下みたいに加えれるのが普通の処理っぽいが、

```
  loss = tf.losses.sparse_softmax_cross_entropy(laels, logit)
  regularization_losses = tf.losses.get_regularization_losses()
  loss = tf.add_n([loss] + regularization_losses)
```

regularization_lossesがパラメータ数に依存してしまって適切なregularizerの値を決めるのが難しい。
中でadd_nを呼ぶ単数形のget_regularization_lossというのがあるので、これを使って以下みたいにした。

```
  loss = tf.losses.sparse_softmax_cross_entropy(laels, logit)
  regularization_loss = tf.losses.get_regularization_loss()
  loss = loss+L2_PENALTY*regularization_loss
```

L2_PENALTYは自分の環境だと1e-5くらいのオーダー。

これ、本当はパラメータ数で割りたいのだが、良い方法は無いのかなぁ。add_nよりreduce_meanとか？
ただパラメータ数の影響をゼロにしたい訳でも無いんだよなぁ。

### BatchNormalizationは別の配慮も必要

regularizationとは別件だが、BatchNormalizationは移動平均を更新する為、update_opを溜めてfitでよきにはからう、という作りになっているので、これもtf.keras下は使えない。

BatchNormalizationも関数として使うにはtf.layers下のを使う必要がある。

この時はupdate_opの方を細工する必要があって、それはtf.contrib.training.create_train_opを使う、とある。
tf.contrib下は廃止という話だったがこの辺がどうなるかは良く分かってない。

```
  train_op = tf.contrib.training.create_train_op(loss, optimizer)
```

### 全部がtf.layersにある訳では無い

例えば自分が使っているものだと、以下はtf.layers下には無いのでtf.keras下を使う必要がある。

- Activation
- GlobalMaxPooling1D
- SpatialDropout1D
- GRU

ちなみにGlobalMaxPooling1Dはtf.layers下には無いが、MaxPooling1Dはある。
全部tf.layersにあってそれだけ使え、とかなら分かりやすいのだがなぁ。

ちなみにtf.layers.MaxPooling1Dは、tf.keras.MaxPooling1Dには認められていたstridesにNoneを指定すると怒られるチェックが入っている。（なんで！？）

