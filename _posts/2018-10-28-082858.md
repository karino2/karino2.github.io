---
title: "論文読み：Neural Models for Information Retrieval"
layout: page	
---

[arxiv:Neural Models for Information Retrieval](https://arxiv.org/abs/1705.01509)

### 読もうと思った動機

機械学習の勉強会で、USの特許データでこれまで勉強した事を試してみよう、となった。

やりたいのは、ある特許を入力したら、「この特許とかぶってるから駄目だよ」と言われそうな「この特許」を探してくる、というのをとりあえずやろうとしている。
過去のペアは手に入る。

で、せっかくなのでニューラルネットでどうにかしたい。
でも結講長いテキストに対してある種の類似テキストを探してくる、というのをどうやったらいいか分からない。
幾つか思いつく方法はあるが、まずは既存の研究を知っておこう、と思い、とりあえずこの論文を読んで見る。

### 論文の構成

一章の最後に構成が書いてあるのでメモしておこう。

- 2章 IR入門（ニューラルネット以外の部分）
- 3章 ニューラルIRモデルの概要
- 4章 教師なしのembeddingの学習と類似度
- 5章 IRでそのembeddingどう使うかの具体例
- 6章 IRで使われるDeepなモデルの基礎
- 7章 IRでDeepなモデルをどう使うの具体例
- 8章 future workとかdiscussionとか

という感じか。

## 2章 IR全般の話

### Mean average precisionが分からず

定義式4の、$${Precision}_{q, i}$$がなんなのか分からない。
ググって見ると、[What you wanted to know about Mean Average Precision](http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/)というページが引っかかり、
どうもこれはトップからi番目までのprecisionっぽい、という理解に至る。

つまり、以下の式という事かな？

![images/2018-10-28-082858/0000.jpg]({{"/assets/images/2018-10-28-082858/0000.jpg" | absolute_url}})

つまりトップiのうち、あたりの数だ。

この式と4式をあわせて考えると、
どうなるんだ？

例えば0番目と2番目が外れて、1番目と3番目が当たる場合を考えると、

![images/2018-10-28-082858/0001.jpg]({{"/assets/images/2018-10-28-082858/0001.jpg" | absolute_url}})

こんな感じか。で、このPrecの3にも1での当たりが含まれるので、最初の方の当たりの方が重みが重くなるのだな。なるほど。

