---
title: "論文読み：Neural Models for Information Retrieval"
layout: page	
---

[arxiv:Neural Models for Information Retrieval](https://arxiv.org/abs/1705.01509)

### 読もうと思った動機

機械学習の勉強会で、USの特許データでこれまで勉強した事を試してみよう、となった。

やりたいのは、ある特許を入力したら、「この特許とかぶってるから駄目だよ」と言われそうな「この特許」を探してくる、というのをとりあえずやろうとしている。
過去のペアは手に入る。

で、せっかくなのでニューラルネットでどうにかしたい。
でも結講長いテキストに対してある種の類似テキストを探してくる、というのをどうやったらいいか分からない。
幾つか思いつく方法はあるが、まずは既存の研究を知っておこう、と思い、とりあえずこの論文を読んで見る。

### 論文の構成

一章の最後に構成が書いてあるのでメモしておこう。

- 2章 IR入門（ニューラルネット以外の部分）
- 3章 ニューラルIRモデルの概要
- 4章 教師なしのembeddingの学習と類似度
- 5章 IRでそのembeddingどう使うかの具体例
- 6章 IRで使われるDeepなモデルの基礎
- 7章 IRでDeepなモデルをどう使うの具体例
- 8章 future workとかdiscussionとか

という感じか。

## 2章 IR全般の話

### Mean average precisionが分からず

定義式4の、$${Precision}_{q, i}$$がなんなのか分からない。
ググって見ると、[What you wanted to know about Mean Average Precision](http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/)というページが引っかかり、
どうもこれはトップからi番目までのprecisionっぽい、という理解に至る。

つまり、以下の式という事かな？

![images/2018-10-28-082858/0000.jpg]({{"/assets/images/2018-10-28-082858/0000.jpg" | absolute_url}})

つまりトップiのうち、あたりの数だ。

この式と4式をあわせて考えると、
どうなるんだ？

例えば0番目と2番目が外れて、1番目と3番目が当たる場合を考えると、

![images/2018-10-28-082858/0001.jpg]({{"/assets/images/2018-10-28-082858/0001.jpg" | absolute_url}})

こんな感じか。で、このPrecの3にも1での当たりが含まれるので、最初の方の当たりの方が重みが重くなるのだな。なるほど。

### Normalized discounted cumulative gain

良くわからんので元論文を見ると、著者のホームページで公開されてた。

結果ドキュメントのリストをスコアのリストに置き換えて先頭から累積分布関数みたく足していくのがCumulative Gain。
で、後ろに行くほど価値を割り引いて足し合わせるのがDCGだが、この割引はあんまり急過ぎると、二番目以降の価値を過小評価しすぎるので、ちょっとずつ減衰するのがいいからlogくらい使っとけ、という程度の意味合いらしい。

IDCGは理想的なスコアのリストでこれを計算した物、との事。
元論文ではrelevanceを0から3までのスコアにしてたが、この論文では0, 1を前提にしてるので、1な物をトップの方に全部並べたスコアという事ですね。

### Dependence modelあまりから読み飛ばす事に

キリが無いな、という事で、この辺はどういう物かを眺めるだけに留めて、必要になったら元論文をたどってちゃんと理解する事にしよう。

Dependence modelはなんちゃらwindowのあたりが良く分からないが、n-gramをどうにか使う事で、完全にtermが一致してなくても何か似てれば引っかかるようにする物らしい。

PRFはクエリと関連するドキュメント群を取ったあとに、それらのドキュメントから言語モデルなどを作って最終的に取り出すドキュメント群を探すという二段階の仕組み。 
ノーテーションを確認するとTは全ボキャブラリとの事。

18式ではクエリからtが得られる確率を、R1のドキュメントからクエリの単語が得られる確率で重みづけしたtが得られる確率で補正している。
これとドキュメントの言語モデルとのKLダイバージェンスをスコアとするらしい。

