---
title: "Goodfellow本を最後まで読んでの感想"
date: 2018-06-28 14:29:10
---

GoodfellowのDeep Learningという本を、5/20から読んでいて、6/28現在、無事読み終わった。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0262035618&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

関連論文なども大量に読まないと理解出来ないように書かれている、ある意味イジワルな本なのでかなり大変だったが、得る物も大きかった。

せっかくなので全体的な感想を書きたい。

### 関連エントリ

1. [GoodfellowのDeepLearning本を読む](https://karino2.github.io/2018/05/22/212.html)  
読んでる間の計算とかメモ、感想など（膨大）
2. [9章まで読んだ段階の、Goodfellow本の感想](https://karino2.github.io/2018/06/04/218.html)

上記の1は、日本で一番長くGoodfellow本について何か書いた物になってると思う。世界でも一番じゃないか？知らないけど。

# この本は、単体ではわざと分からないように書かれている

最初に強調したい所はここ。

この本は一見すると線形代数とか確率論とかback propagationとか解説しているので、他の本を参照しなくても一通り分かるように書かれてるフリをしているが、最後まで読んだ結果、それはフェイントだ、と私は結論づけた。

この本は参照されている文献を読む事を前提に書かれている。

そう思う根拠は、幾つかのGoodfellow自身が書いた論文を参照する時でも、わざと本文の方に数行で書けるキモとなる数式を書かなかったりしているからだ。
本人がそれを分かってないとは思えない。

だが紙面の都合で短くしている、という訳でも無く、著者の感想みたいな事などはその後にそれなりに行数を割いて書いている。

だから元論文を読まないと分からないように、わざと抜いた、と自分は理解した。

幾つかの論文は本文を読むだけで概要が分かるようになっていて、幾つかの論文はわざと概要が分からないように書かれている。
そして、概要がわざと分からないように書かれている論文は重要な物が多く、それらを読んでいく事で、最近の生成モデルを読むだけでは分からない、研究の文脈みたいな物が分かるように配慮されている。

特にPart 3はその傾向が強い。

### この本の対象読者

この本は論文を読む代わりにならないし、論文を読む助けにもならない。
論文を読んだあとに、その理解を深める為の本だ。

だからこの本を使う為には「既に自分で論文を読む力がある」事が前提となる。
実際自分のよんでる時のメモ、[GoodfellowのDeepLearning本を読む](https://karino2.github.io/2018/05/22/212.html)でも、相当の数の元論文を読んでるのが分かると思う。

これはintroとかPart 1を読んだ印象からは全く想像できない内容だった。
そして私と同じ事を言ってる人をあまり見かけないのも謎だ。みんな読んでないんじゃね？

論文を独力で読んでいける必要があるので、Deep Learningとは何かを知りたい、という人には全く向いてない。

また、機械学習や数学が強い人が、Deep Learningの事を知りたい、という目的にも向かない。

この本は、ある程度この業界で研究や仕事をやっていて、どういうモデルがどういう風に良く使われていて、どのくらいちゃんと動くのか、みたいな事を知っているのが前提となる。

だからdrop outとかbatch normalizationとかは既に知ってて使ってる、という人向けに思う。
というのは、具体的に触るのに必要な情報が足りてないが、触ってないと分からない事が結構含まれているから。

この本は分厚さ的にも序盤の内容的にも、「この本を最初から最後まで読めばDeep Learningを知らなかった若者が最近の研究の一歩手前まで行ける！」という事を期待しがちに思うけれど、残念でした。そういう本ではありません。

Deep Learningの経験をある程度持ってててそれなりに最近の論文を幾つか読んでいて、PRMLとかある程度読んでて、PGMとかMCMCとかもどこかで学んでて、それなりに確率論的なバックグラウンドがある人が読む本になってます。
相当要求水準高い。

そのかわり、そういう人が読むと、GANの論文とか突然読んだ時のあの「なんだか分からない感じ」が綺麗に払拭される。
いつも話題の論文とか実務に必要な論文からさかのぼって幾つかの関連論文を読んでいってなんとなく必要な事を知っている、という感じの人の土台を凄いしっかりした物にしてくれる。

これはそういう本だと思う。

### この本はDeep Learningの仕事をしている人には、素晴らしい本だ

最初の方は文句もかなりあった本書だけど、最後まで読んだ結果、自分には凄く勉強になった。
自分以外の人のことは良く分からないので、やはり自分にとってどうか、で本は評価すべき、と思う。

その観点で行けば、この本は素晴らしい本だ。
こんなに勉強になるDeep Learning本は他に考えられない。
世の中が期待してたのはこういう本では無かった気もするが、自分にはとても良かった。
