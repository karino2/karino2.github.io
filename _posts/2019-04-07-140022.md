---
title: "MacKayのInformation Theory, Inference, and Learning Algorithms"
layout: page	
---

勉強会で読む事にしたMacKayの情報理論の本。Cover and Thomasと並びよく参照される情報理論の定番教科書。
こちらにはベイズと機械学習の話題がある。

Kindle版は無いが、pdfがある。

[Information Theory, Inference, and Learning Algorithms](http://www.inference.org.uk/itprnn/book.html)



# 一章

最初にスターリンの公式と二項分布がある。
準備体操に手を動かしてみるか。

### Example 1.1 偏りありのコイン投げ

表かfのコイン投げ。N回投げて表がr回出る確率と、rの平均と分散を求める。

まずは表がrの確率。

![images/2019-04-07-140022/0000.jpg]({{"/assets/images/2019-04-07-140022/0000.jpg" | absolute_url}})

右下にごみが入ってるが気にしない。
次は平均。

![images/2019-04-07-140022/0001.png]({{"/assets/images/2019-04-07-140022/0001.png" | absolute_url}})

これどう計算するんだっけ。二項定理使って微分すれば出そう？

![images/2019-04-07-140022/0002.png]({{"/assets/images/2019-04-07-140022/0002.png" | absolute_url}})

ふむ、Nfか。まぁそりゃそうだな。解説見ても一回の平均がfだからN回でNf、としてる。

次は分散。

![images/2019-04-07-140022/0003.png]({{"/assets/images/2019-04-07-140022/0003.png" | absolute_url}})

rの二乗の期待値を求める問題に帰着された。試行が独立なら別々の期待値の和だよな。r二乗の期待値は...1を二乗しても1だからfか？

すると、$$Nf-Nf^2$$だから、$$Nf(1-f)$$か。

### スターリンの公式の話

コンビネーションの計算をしておく。

![images/2019-04-07-140022/0004.jpg]({{"/assets/images/2019-04-07-140022/0004.jpg" | absolute_url}})

