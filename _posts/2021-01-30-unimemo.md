---
title: 自分の書いたブログやtweetなどをローカルでgrepできるようにしよう
layout: page
---
[自分が過去に書いたモノを一箇所にまとめたい](https://karino2.github.io/2021/01/22/logging.html)の話を実際に実現しよう、と決心する。

### システムの名前は unimemo とする

とりあえず名前をつける。unified memoという事でunimemoに決定。

レポジトリ: [https://github.com/karino2/unimemo](https://github.com/karino2/unimemo)

### 基本的な考え

まずGoogle Drive上に置く事にする。
対象としてはlivejournalとかmixiとかtweetとかGoogle Keepとかいろいろあるので、
それぞれのデータからmarkdownへのコンバーターをそれぞれ書く、というスタンスにする。

unimemoのルートを`/`で表すと、まずexportした生のデータを/original下に置く。

- `/original/Keep`
- `/original/mixi`
- `/original/twitter`
- `/original/...`

など。このデータはコンバートせず、何らかのexportしたものをそのまま置く事にする。
新しくデータをexportしたらここにそのまま置くだけで良い。

で、これをmarkdownにコンバートする。それはmdフォルタとする。
フォルダとしては、月までを掘って、中をどうまとめるかはコンバーターに任せる。
例えばtweetは一日単位を1ファイルにまとめる。
ブログは1記事を1ファイル、など。

- `/original`
- `/md/2020/01`
- `/md/2020/02`
- `/md/...`

ファイル名は、export元_日付_任意の文字.mdとする。任意の文字はoptional（ブログのタイトルなどを入れる）。
例えばtwitter_2020_01_07.mdとか、mixi_2020_01_07_153732.mdとか。

どういうマークダウンを作るかはコンバーター任せ。

画像は現時点ではoriginalの下にそのまま相対リンクで貼ってしまえばいいかなぁ。
数百MBというオーダーなのでmd下にコピーしてしまってもいいんだけど、とりあえずはやめておこう。

grepはmdフォルダ下で行う。

### ビュワー（は後回し）

また、マークダウンのビュワーはそのうち何か作りたい。ローカルにhttp立ち上げて月ごとにまとめるビューを、
適当なファイル数ごとにページネーションつける感じのモノと、export元ごとに見れるようなビューが欲しいかなぁ。
ただこれは後回しで良かろう。とりあえずgrep出来て、VSCodeのmarkdown previewerとかで1ファイルは見れるだろうし。

### インクリメンタルに作業出来る事を重視する

一気に作ろうとするとやる気が出ないので、まず最低限の所から始めたい。
とりあえずサービスが消えてしまう前にexportするのが第一歩。
これも全部exportしようとかいうとやる気が出ないので、とりあえず必要なtwitterから始めて徐々に進めたい。

とりあえずoriginal下に置くだけなら害は無いので、コンバーターを書くのは後回しに出来る。
気力が湧いた時にexportしていって、気力が湧いた時にコンバーターを書きたい。
ビュワーとか作る前にとりあえずexportだけ出来るように決めてしまうのが大切（たぶん）。

### 作業の進め方

とりあえずunimemoというフォルダにプログラム関連を置く。
unimemo.fsprojを作り、Scratch.fsxというファイルで適当にデータをつつきつつ、
いいところまで行ったら.fsファイルに切り出していこう。
まぁコンバートなんて一回やればしばらくはいいのだから、fsx上でゆるゆるやって切り出しとか考えなくてもいいかもしれない。

## twitter

一番のモチベーションは過去のtweetを適当に検索して、それがいつだったかを知りたい、なので、まずはtwitterから作業する。

### exrpot方法

twitterの設定とプライバシーから、アカウント＞データのアーカイブをダウンロード でパスワードを入れてリンクを押すと、３日後くらいにアプリやサイトに通知が来る。
リンクを押した段階ではなんか終わったふうに見えるのに何もリンクが無いので混乱するが、待てば良いだけ。

ダウンロードした結果はjsonだけが入ったtweet.jsと画像。

### FSharp.Dataのセットアップ

jsonのパースはFSharp.Dataを使う事にする。

まずはunimemo.fsprojのファイルにFSharp.Dataのエントリを足してビルド。

```
  <ItemGroup>
    <PackageReference Include="FSharp.Data" Version="3.3.3" />
    <Compile Include="Program.fs" />
  </ItemGroup>
```

次にScratch.fsxの先頭に以下のように書いてみる。

```
#r "bin/Debug/net5.0/FSharp.Data.dll"
```

すると、なんか`FSharp.Data.DesignTime.dll`が無い的な事を言われる。何これ？

以下のissueっぽいが、解決策がよくわからないな。
[Referencing Fsharp.Data.dll from the script produces design time-related error (#647)](https://github.com/fsprojects/FSharp.Data/issues/647)

分からないのでfsharp.dataのnugetパッケージをとってきて該当dllを抜き出そう。

[https://www.nuget.org/packages/FSharp.Data/](https://www.nuget.org/packages/FSharp.Data/)から、Version 3.3.3を選んで右側のDownload Packageを選ぶ。
拡張子をzipにして開いてみる。dllの大きさを比較すると、`lib/netstandard2.0/FSharp.Data.dll`が我々の参照しているdllっぽい？
なんでnet5.0じゃないのかは良く分からないが、まぁいい。
`lib/netstandard2.0/FSharp.Data.DesignTime.dll`を、プロジェクトの`bin/Debug/net5.0/`にコピーする。

fsxからロードしたら動いたヽ(´ー｀)ノ　

### jsonのロード関連のメモ

tweet.jsは先頭の行を細工すればjsonになりそうなので細工するコードを書く。

json自体は70MBくらい。

スキーマを定義するのはかったるいなぁ、と思っていた所、FSharp.DataはTypeProviderという仕組みで型を動的に生成して、
さらにそれを活かしてデータからスキーマをguess出来るらしい。(・∀・)ｲｲﾈ!!

という事でtweet.jsの一行目を直したものをtemp_tweet.jsonという名前で吐く事にし、これを

```
type TweetParser = JsonProvider<"temp_tweet.json">
let data = TweetParser.GetSamples()
```

これでロード出来ているっぽい。まぁまぁ一瞬。2秒くらいか？ちょっと待つがそのくらい。70MBくらいのデータがこれだけ早くパース出来るなら十分やね。

型はTweetParser下に作られるっぽい。だいたい良さそうだが、MediaとMedia2というのが出来ている。どう違うんだろう？
こういう生成された型をダンプする方法って無いのかしら？

良くわからんので、

```
let hoge2 x:TweetParser.Media =
  x.
```

という感じでインテリセンスしたものを目視で比べると（ゆとり）、どうもMedia2の方にだけAdditionalMediaInfoというのがあるらしい。
どういう事だ？とこれを含んでるっぽいjsonを一つだけ取り出してロードしていろいろ試した所、
このMedia2は`data.[0].Tweet.ExtendedEntities`の下のMediaの型っぽいな。

### コンバーター関連のメモ。

とりあえずリンクと画像はちゃんと扱おう。
リンクはshortじゃない元の奴に戻す。画像はmarkdownのインラインのにする。

あとは1日単位で一つのmarkdownとして、中身は以下でいいか？

```
### 2007-05-15のツイート

*2007-05-15 15:55:04*  
ここにツイート

*2007-05-15 17:23:04*  
ここに別のツイート
```

日付は鬱陶しいが、仕方ないか。

ハッシュに突っ込みたいがどういうハッシュにするかなぁ。月か日だが、どっちがいいか。日でいいか。
空の日の影響はどのくらいあるかな？
日付でfor文回すと、今年てtwitterはじめて14年くらいか？なので、365x14か。まぁこの位なら一瞬だな。じゃあ日でハッシュに突っ込んで、
月ごとにDateTimeを31個生成して引いてみる感じでいいか。