---
title: "サイコロ本（Foundations of Statistical Natural Language Processing）を読むぞ！"
layout: page	
---

BERTがなかなか良さそうなので、次はNLPやろうかな、と思い、サイコロ本を読んでおこう、となる。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0262133601&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

自分の認識だとこの本は定番の教科書だがニューラルネット以前の奴という位置づけ。
まぁembeddingsとかencoder-decoderとかは知ってるので、むしろこういう奴の方が自分には必要かな、と思い読む事に。

### 自分の前提知識

自分がこれまで読んだ本。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4339027545&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

昔機械翻訳の研究をやろうか、と思った事があって、研究室を選ぶ為に教科書を学ぼう、と思った事があった。
seq2seqとかより前の頃。
で、この教科書読んでたら、自分がドクター取る頃にはこの問題片付いてそうだな、と思ってやめた。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4061529048&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

トピックモデルが知りたくてこの本読んだ事がある。一応ちゃんと理解した（もう忘れたが）

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4061529242&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

ちゃんとRNN使った自然言語処理を理解したいと思って読んだ。結講真面目に読んだ気がする。

その他seq2seqとその周辺の論文とか、word2vecとかは一応読んで、だいたい理解してたと思う（もう忘れたが）

またグラフィカルモデルは結講真面目に勉強してて、HMMとかは実装も数学的な話は証明とかも割と真面目にやってて結講得意。

という事で何も知らないという訳でも無いがちゃんと勉強した、という訳でも無い状態なので、基礎をちゃんと勉強してみよう、と思った次第。

ただこの辺の式追うのはそんなに困ってないので、式変形とかを頑張って追うかは未定。読んでから考えます。

### Road map

全4部構成で、Part1は数学とかlinguisticとかの入門らしい。さすがに飛ばし読みでいいか？

Part2はWord。
ここが一番真面目に読みたい所かな？
collocation、disambiguation、attachment disambiguitiesとかが大切らしい。たぶん知らなさそう。

Part3が文法。
最近あんま見ない話題ね。

Part4が応用。
IRとかテキストのカテゴライズとかの話らしいので、意外と興味深いかも。

